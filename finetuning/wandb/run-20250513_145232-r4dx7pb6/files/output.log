I0513 14:52:32.284289 137707396454208 finetune.py:44] Loading pre-trained model...
Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 117597.31it/s]
I0513 14:52:34.866640 137707396454208 octo_module.py:219] repeating task tokens at each timestep to perform cross-modal attention
I0513 14:52:38.484717 137707396454208 checkpointer.py:164] Restoring item from /home/hyperdog/.cache/huggingface/hub/models--rail-berkeley--octo-small-1.5/snapshots/dc9aa3019f764726c770814b27e4ab0fc6e32a58/300000/default.
I0513 14:52:38.952255 137707396454208 checkpointer.py:166] Finished restoring checkpoint from /home/hyperdog/.cache/huggingface/hub/models--rail-berkeley--octo-small-1.5/snapshots/dc9aa3019f764726c770814b27e4ab0fc6e32a58/300000/default.
I0513 14:52:39.674890 137707396454208 finetune.py:51] Loading finetuning dataset...
I0513 14:52:39.678844 137707396454208 dataset_info.py:578] Load dataset info from /home/hyperdog/tensorflow_datasets/core_sample_dataset/1.0.0
I0513 14:52:39.805757 137707396454208 logging_logger.py:49] Constructing tf.data.Dataset core_sample_dataset for split all, from /home/hyperdog/tensorflow_datasets/core_sample_dataset/1.0.0
WARNING:tensorflow:AutoGraph could not transform <function _gcd_import at 0x7d3e80693400> and will run it as-is.
Cause: Unable to locate the source code of <function _gcd_import at 0x7d3e80693400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
W0513 14:52:39.994176 137707396454208 ag_logging.py:142] AutoGraph could not transform <function _gcd_import at 0x7d3e80693400> and will run it as-is.
Cause: Unable to locate the source code of <function _gcd_import at 0x7d3e80693400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0513 14:52:40.248462 137707396454208 api.py:446] Sampling uniformly across keys: ['language_instruction']
I0513 14:52:40.349334 137707396454208 data_utils.py:113] Loading existing dataset statistics from /home/hyperdog/tensorflow_datasets/core_sample_dataset/1.0.0/dataset_statistics_8bbdfa3802d95d627c4f516884aa95be8ce33d4bd8fadbff96e6b465c2c469e9.json.
I0513 14:52:40.371089 137707396454208 logging_logger.py:49] Constructing tf.data.Dataset core_sample_dataset for split train[:95%], from /home/hyperdog/tensorflow_datasets/core_sample_dataset/1.0.0
I0513 14:52:40.401875 137707396454208 api.py:446] Sampling uniformly across keys: ['language_instruction']
I0513 14:52:57.658731 137707396454208 finetune.py:123] Updating model for new observation & action space...
I0513 14:52:58.506460 137707396454208 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
I0513 14:52:58.536629 137707396454208 tokenizers.py:124] No task inputs matching image_wrist were found. Replacing with zero padding.
I0513 14:52:58.583057 137707396454208 octo_module.py:219] repeating task tokens at each timestep to perform cross-modal attention
W0513 14:52:58.584892 137707396454208 block_transformer.py:410] Prefix groups:
W0513 14:52:58.584981 137707396454208 block_transformer.py:412] PrefixGroup(name=task_language, shape=(1, 16, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0513 14:52:58.585036 137707396454208 block_transformer.py:418] Timestep groups:
W0513 14:52:58.585081 137707396454208 block_transformer.py:420] TimestepGroup(name=obs_primary, shape=(1, 2, 256, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0513 14:52:58.585122 137707396454208 block_transformer.py:420] TimestepGroup(name=obs_wrist, shape=(1, 2, 64, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0513 14:52:58.585161 137707396454208 block_transformer.py:420] TimestepGroup(name=obs_proprio, shape=(1, 2, 7, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0513 14:52:58.585195 137707396454208 block_transformer.py:420] TimestepGroup(name=obs_task_language, shape=(1, 2, 16, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0513 14:52:58.585229 137707396454208 block_transformer.py:420] TimestepGroup(name=readout_action, shape=(1, 2, 1, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    readout_action: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
[3m                                 Attention Mask                                 [0m
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”³â”â”â”â”³â”â”â”“
â”ƒ[1m                                    [0mâ”ƒ[1m   [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ
â”ƒ[1m                                    [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ
â”ƒ[1m                                    [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ
â”ƒ[1m [0m[1m                                  [0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â•‡â”â”â”â•‡â”â”â”©
â”‚ task_language (16 tokens)          â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 obs_primary (256 tokens)       â”‚   â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 obs_wrist (64 tokens)          â”‚   â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 obs_proprio (7 tokens)         â”‚   â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 obs_task_language (16 tokens)  â”‚   â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 readout_action (1 tokens)      â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚   â”‚   â”‚  â”‚   â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 obs_primary (256 tokens)       â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 obs_wrist (64 tokens)          â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 obs_proprio (7 tokens)         â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 obs_task_language (16 tokens)  â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 readout_action (1 tokens)      â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚  â”‚   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”´â”€â”€â”€â”´â”€â”€â”˜

[3m                               OctoModule Summary                               [0m
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m [0m[1mpath         [0m[1m [0mâ”ƒ[1m [0m[1mmodule       [0m[1m [0mâ”ƒ[1m [0m[1minputs       [0m[1m [0mâ”ƒ[1m [0m[1moutputs      [0m[1m [0mâ”ƒ[1m [0m[1mparams      [0m[1m [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚               â”‚ OctoModule    â”‚ -             â”‚ - obs:        â”‚              â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ [2mbool[0m[1,2,343] â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚   obs_primarâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚ [2mbool[0m[1,2,256] â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚   obs_propriâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚ [2mbool[0m[1,2,7]   â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚   obs_task_lâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚ [2mbool[0m[1,2,16]  â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚   obs_wrist:  â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚ [2mbool[0m[1,2,64]  â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚   readout_acâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚   task:       â”‚              â”‚
â”‚               â”‚               â”‚ - [2mbool[0m[1,2]   â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚   verbose:    â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚   task_languâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚               â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚               â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ - action:     â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ OctoTransforâ€¦ â”‚ -             â”‚ obs:          â”‚ obs_primaryâ€¦ â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚   mask:       â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ [2mbool[0m[1,2,343] â”‚ obs_proprioâ€¦ â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚   tokens:     â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ obs_wrist_pâ€¦ â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚ obs_primary:  â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚   mask:       â”‚ readout_actâ€¦ â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚ [2mbool[0m[1,2,256] â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚   tokens:     â”‚ task_languaâ€¦ â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚     proprio:  â”‚ obs_proprio:  â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚   mask:       â”‚ [1m1,265,664 [0m   â”‚
â”‚               â”‚               â”‚     timestep: â”‚ [2mbool[0m[1,2,7]   â”‚ [1;2m(5.1 MB)[0m     â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ obs_task_lanâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚ [2mbool[0m[1,2,16]  â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚ obs_wrist:    â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚ [2mbool[0m[1,2,64]  â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚ readout_actiâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚ task:         â”‚              â”‚
â”‚               â”‚               â”‚ - [2mbool[0m[1,2]   â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚   verbose:    â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚ task_languagâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚               â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚               â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder       â”‚ FlaxT5Stack   â”‚ attention_maâ€¦ â”‚ attentions:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,1]    â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ deterministiâ€¦ â”‚ cross_attentâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ input_ids:    â”‚ hidden_stateâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,1]    â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ output_attenâ€¦ â”‚ last_hidden_â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ output_hiddeâ€¦ â”‚ past_key_valâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ return_dict:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ shared        â”‚ Embed         â”‚ [2mint32[0m[1,1]    â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/dropâ€¦ â”‚ Dropout       â”‚ -             â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,1,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ deterministiâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/block â”‚ FlaxT5BlockCâ€¦ â”‚ -             â”‚ attentions:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,1,â€¦ â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚ cross_attentâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ attention_maâ€¦ â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,1]    â”‚ hidden_stateâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚   determinisâ€¦ â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚ last_hidden_â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   encoder_atâ€¦ â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ None          â”‚ past_key_valâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚   encoder_hiâ€¦ â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ None          â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   init_cache: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   output_attâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   output_hidâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/finaâ€¦ â”‚ FlaxT5LayerNâ€¦ â”‚ [2mfloat32[0m[1,1,â€¦ â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ LanguageTokeâ€¦ â”‚ -             â”‚ mask:         â”‚ [1m109,628,544 [0m â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚ [2mbool[0m[1,16]    â”‚ [1;2m(438.5 MB)[0m   â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ tokens:       â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,16â€¦ â”‚ [2mfloat32[0m[1,16â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384] â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[768â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m295,296 [0m[1;2m(1.2[0m â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2mMB)[0m          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ ImageTokenizâ€¦ â”‚ -             â”‚ mask:         â”‚ [1m1,058,048 [0m   â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚ [2mbool[0m[1,2,256] â”‚ [1;2m(4.2 MB)[0m     â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ tokens:       â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384] â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[512â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m196,992 [0m     â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2m(788.0 KB)[0m   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ ImageTokenizâ€¦ â”‚ -             â”‚ mask:         â”‚ [1m1,058,048 [0m   â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚ [2mbool[0m[1,2,64]  â”‚ [1;2m(4.2 MB)[0m     â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ tokens:       â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384] â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[512â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m196,992 [0m     â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2m(788.0 KB)[0m   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ LowdimObsTokâ€¦ â”‚ -             â”‚ mask:         â”‚              â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ tokens:       â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384] â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[256â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m98,688 [0m      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2m(394.8 KB)[0m   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ BlockTransfoâ€¦ â”‚ - -           â”‚ - -           â”‚ [1m21,294,336 [0m  â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚ [1;2m(85.2 MB)[0m    â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ task_language â”‚ task_language â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ - -           â”‚ - -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,256] â”‚ [2mbool[0m[1,2,256] â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ obs_primary   â”‚ obs_primary   â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   -           â”‚   -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,64]  â”‚ [2mbool[0m[1,2,64]  â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ obs_wrist     â”‚ obs_wrist     â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   -           â”‚   -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,7]   â”‚ [2mbool[0m[1,2,7]   â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ obs_proprio   â”‚ obs_proprio   â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   -           â”‚   -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,16]  â”‚ [2mbool[0m[1,2,16]  â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ obs_task_lanâ€¦ â”‚ obs_task_lanâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   -           â”‚   -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       readouâ€¦ â”‚       readouâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ readout_actiâ€¦ â”‚ readout_actiâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   verbose:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action  â”‚ L1ActionHead  â”‚ - obs:        â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,343] â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   obs_primarâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,256] â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   obs_propriâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,7]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   obs_task_lâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,16]  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   obs_wrist:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,64]  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   readout_acâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task:       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_languâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_actionâ€¦ â”‚ MAPHead       â”‚ - mask:       â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ probe:       â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚   tokens:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚ [1m1,774,080 [0m   â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚ [1;2m(7.1 MB)[0m     â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_actionâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[28]  â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m10,780 [0m[1;2m(43.1[0m â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2mKB)[0m          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚[1m [0m[1m             [0m[1m [0mâ”‚[1m [0m[1m             [0m[1m [0mâ”‚[1m [0m[1m             [0m[1m [0mâ”‚[1m [0m[1m        Total[0m[1m [0mâ”‚[1m [0m[1m136,877,468 [0m[1m [0mâ”‚
â”‚[1m               [0mâ”‚[1m               [0mâ”‚[1m               [0mâ”‚[1m               [0mâ”‚[1m [0m[1;2m(547.5 MB)[0m[1m  [0m[1m [0mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1m                                                                                [0m
[1m                    Total Parameters: 136,877,468 [0m[1;2m(547.5 MB)[0m[1m                    [0m
I0513 14:53:02.950131 137707396454208 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
I0513 14:53:02.985544 137707396454208 tokenizers.py:124] No task inputs matching image_wrist were found. Replacing with zero padding.
I0513 14:53:03.018257 137707396454208 octo_module.py:219] repeating task tokens at each timestep to perform cross-modal attention
I0513 14:53:07.335329 137707396454208 compiler.py:323] Persistent compilation cache hit for 'jit__init'
I0513 14:53:07.355576 137707396454208 train_utils.py:405] ########## Parameters skipped during model loading: ##########
I0513 14:53:07.355798 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.bias
I0513 14:53:07.355856 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.scale
I0513 14:53:07.355892 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.bias
I0513 14:53:07.355925 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.kernel
I0513 14:53:07.355955 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.bias
I0513 14:53:07.355984 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.kernel
I0513 14:53:07.356016 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.bias
I0513 14:53:07.356045 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.kernel
I0513 14:53:07.356074 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.bias
I0513 14:53:07.356102 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.kernel
I0513 14:53:07.356130 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.bias
I0513 14:53:07.356158 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.kernel
I0513 14:53:07.356186 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.bias
I0513 14:53:07.356214 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.kernel
I0513 14:53:07.356240 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.probe
I0513 14:53:07.356265 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.bias
I0513 14:53:07.356293 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.kernel
I0513 14:53:07.356321 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_pos_embedding
I0513 14:53:07.356347 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.bias
I0513 14:53:07.356371 137707396454208 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.kernel
I0513 14:53:07.357119 137707396454208 train_utils.py:250] Freezing parameters that include the following keys: ['*hf_model*'].
I0513 14:53:07.358919 137707396454208 train_utils.py:286] Num trainable params: 27,248,924.
I0513 14:53:07.358995 137707396454208 train_utils.py:287] Num frozen params: 109,628,544.
I0513 14:53:07.359042 137707396454208 train_utils.py:288] To see a detailed list of frozen params, set logging level to DEBUG.
I0513 14:53:07.993956 137707396454208 finetune.py:185] Starting finetuning...
  0%|                                                 | 0/50000 [00:00<?, ?it/s]I0513 14:53:08.533791 137707396454208 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
I0513 14:53:08.627762 137707396454208 tokenizers.py:124] No task inputs matching image_wrist were found. Replacing with zero padding.
I0513 14:53:08.700084 137707396454208 octo_module.py:219] repeating task tokens at each timestep to perform cross-modal attention
/home/hyperdog/anaconda3/envs/octo/lib/python3.10/site-packages/jax/_src/compiler.py:365: UserWarning: Error reading persistent compilation cache entry for 'jit_train_step': XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/hlo/ir/hlo_module.cc:511) !ContainsKey(instruction_names, instruction->name()) Instruction name is not unique: constant_4820
  warnings.warn(
I0513 14:53:28.510618 137707396454208 compilation_cache.py:101] Writing jit_train_step to persistent compilation cache with key jit_train_step-f08f318fcb1f0b2d903786d0284a45e87e0a896f9395c1fdcbc2b4308fca82e1.
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 9999/50000 [33:18<2:08:04,  5.21it/s]I0513 15:26:27.310437 137707396454208 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/9999.orbax-checkpoint-tmp-1747139187275483/default.
I0513 15:26:28.193086 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/9999.orbax-checkpoint-tmp-1747139187275483/default.orbax-checkpoint-tmp-1747139187310622 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/9999.orbax-checkpoint-tmp-1747139187275483/default
I0513 15:26:28.193381 137707396454208 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/9999.orbax-checkpoint-tmp-1747139187275483/default`.
I0513 15:26:28.195685 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/9999.orbax-checkpoint-tmp-1747139187275483 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/9999
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 19999/50000 [1:06:49<1:39:49,  5.01it/s]I0513 15:59:57.916527 137707396454208 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/19999.orbax-checkpoint-tmp-1747141197914806/default.
I0513 15:59:58.896800 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/19999.orbax-checkpoint-tmp-1747141197914806/default.orbax-checkpoint-tmp-1747141197916690 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/19999.orbax-checkpoint-tmp-1747141197914806/default
I0513 15:59:58.897036 137707396454208 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/19999.orbax-checkpoint-tmp-1747141197914806/default`.
I0513 15:59:58.898058 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/19999.orbax-checkpoint-tmp-1747141197914806 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/19999
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 29999/50000 [1:39:45<1:04:04,  5.20it/s]I0513 16:32:54.467163 137707396454208 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/29999.orbax-checkpoint-tmp-1747143174465349/default.
I0513 16:32:55.428384 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/29999.orbax-checkpoint-tmp-1747143174465349/default.orbax-checkpoint-tmp-1747143174467315 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/29999.orbax-checkpoint-tmp-1747143174465349/default
I0513 16:32:55.428639 137707396454208 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/29999.orbax-checkpoint-tmp-1747143174465349/default`.
I0513 16:32:55.429928 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/29999.orbax-checkpoint-tmp-1747143174465349 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/29999
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 39999/50000 [2:12:46<33:18,  5.01it/s]I0513 17:05:54.993861 137707396454208 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/39999.orbax-checkpoint-tmp-1747145154992046/default.
I0513 17:05:55.934746 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/39999.orbax-checkpoint-tmp-1747145154992046/default.orbax-checkpoint-tmp-1747145154994023 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/39999.orbax-checkpoint-tmp-1747145154992046/default
I0513 17:05:55.934985 137707396454208 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/39999.orbax-checkpoint-tmp-1747145154992046/default`.
I0513 17:05:55.936238 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/39999.orbax-checkpoint-tmp-1747145154992046 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/39999
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 49999/50000 [2:46:24<00:00,  5.16it/s]I0513 17:39:32.825053 137707396454208 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/49999.orbax-checkpoint-tmp-1747147172823169/default.
I0513 17:39:33.789630 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/49999.orbax-checkpoint-tmp-1747147172823169/default.orbax-checkpoint-tmp-1747147172825206 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/49999.orbax-checkpoint-tmp-1747147172823169/default
I0513 17:39:33.789845 137707396454208 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/49999.orbax-checkpoint-tmp-1747147172823169/default`.
I0513 17:39:33.790905 137707396454208 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/49999.orbax-checkpoint-tmp-1747147172823169 to /home/hyperdog/thesis/checkpoints/night/put_in_the_box_200_no_augmentation/49999
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [2:46:25<00:00,  5.01it/s]
