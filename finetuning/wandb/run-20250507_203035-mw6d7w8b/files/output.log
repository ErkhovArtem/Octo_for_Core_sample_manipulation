I0507 20:30:35.944794 128789240575808 finetune.py:44] Loading pre-trained model...
Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 5648.89it/s]
I0507 20:30:41.827482 128789240575808 octo_module.py:219] repeating task tokens at each timestep to perform cross-modal attention
I0507 20:30:45.427155 128789240575808 checkpointer.py:164] Restoring item from /home/hyperdog/.cache/huggingface/hub/models--rail-berkeley--octo-small-1.5/snapshots/dc9aa3019f764726c770814b27e4ab0fc6e32a58/300000/default.
I0507 20:30:45.763169 128789240575808 checkpointer.py:166] Finished restoring checkpoint from /home/hyperdog/.cache/huggingface/hub/models--rail-berkeley--octo-small-1.5/snapshots/dc9aa3019f764726c770814b27e4ab0fc6e32a58/300000/default.
I0507 20:30:47.118211 128789240575808 finetune.py:51] Loading finetuning dataset...
I0507 20:30:47.121855 128789240575808 dataset_info.py:578] Load dataset info from /home/hyperdog/tensorflow_datasets/core_sample_dataset/1.0.0
I0507 20:30:47.249034 128789240575808 logging_logger.py:49] Constructing tf.data.Dataset core_sample_dataset for split all, from /home/hyperdog/tensorflow_datasets/core_sample_dataset/1.0.0
WARNING:tensorflow:AutoGraph could not transform <function _gcd_import at 0x752214563400> and will run it as-is.
Cause: Unable to locate the source code of <function _gcd_import at 0x752214563400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
W0507 20:30:47.439499 128789240575808 ag_logging.py:142] AutoGraph could not transform <function _gcd_import at 0x752214563400> and will run it as-is.
Cause: Unable to locate the source code of <function _gcd_import at 0x752214563400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0507 20:30:47.687936 128789240575808 api.py:446] Sampling uniformly across keys: ['language_instruction']
I0507 20:30:47.788305 128789240575808 data_utils.py:113] Loading existing dataset statistics from /home/hyperdog/tensorflow_datasets/core_sample_dataset/1.0.0/dataset_statistics_fe8bbf8379648280dcf83efab0375ee4af085e83e56db872bf373cb8e7b0e246.json.
I0507 20:30:47.809014 128789240575808 logging_logger.py:49] Constructing tf.data.Dataset core_sample_dataset for split train[:95%], from /home/hyperdog/tensorflow_datasets/core_sample_dataset/1.0.0
I0507 20:30:47.840861 128789240575808 api.py:446] Sampling uniformly across keys: ['language_instruction']
I0507 20:31:06.057986 128789240575808 finetune.py:118] Updating model for new observation & action space...
I0507 20:31:06.554699 128789240575808 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
I0507 20:31:06.585003 128789240575808 tokenizers.py:124] No task inputs matching image_wrist were found. Replacing with zero padding.
I0507 20:31:06.631165 128789240575808 octo_module.py:219] repeating task tokens at each timestep to perform cross-modal attention
W0507 20:31:06.632894 128789240575808 block_transformer.py:410] Prefix groups:
W0507 20:31:06.632985 128789240575808 block_transformer.py:412] PrefixGroup(name=task_language, shape=(1, 16, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0507 20:31:06.633033 128789240575808 block_transformer.py:418] Timestep groups:
W0507 20:31:06.633079 128789240575808 block_transformer.py:420] TimestepGroup(name=obs_primary, shape=(1, 2, 256, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0507 20:31:06.633119 128789240575808 block_transformer.py:420] TimestepGroup(name=obs_wrist, shape=(1, 2, 64, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0507 20:31:06.633157 128789240575808 block_transformer.py:420] TimestepGroup(name=obs_proprio, shape=(1, 2, 7, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0507 20:31:06.633191 128789240575808 block_transformer.py:420] TimestepGroup(name=obs_task_language, shape=(1, 2, 16, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0507 20:31:06.633227 128789240575808 block_transformer.py:420] TimestepGroup(name=readout_action, shape=(1, 2, 1, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    readout_action: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
[3m                                 Attention Mask                                 [0m
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”â”³â”â”â”³â”â”â”â”³â”â”â”“
â”ƒ[1m                                    [0mâ”ƒ[1m   [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ
â”ƒ[1m                                    [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ
â”ƒ[1m                                    [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ
â”ƒ[1m [0m[1m                                  [0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ[1m [0m[1mâ€¦[0m[1m [0mâ”ƒ[1m  [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â”â•‡â”â”â•‡â”â”â”â•‡â”â”â”©
â”‚ task_language (16 tokens)          â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 obs_primary (256 tokens)       â”‚   â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 obs_wrist (64 tokens)          â”‚   â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 obs_proprio (7 tokens)         â”‚   â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 obs_task_language (16 tokens)  â”‚   â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=0 readout_action (1 tokens)      â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚   â”‚   â”‚  â”‚   â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 obs_primary (256 tokens)       â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 obs_wrist (64 tokens)          â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 obs_proprio (7 tokens)         â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 obs_task_language (16 tokens)  â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ x â”‚ x â”‚  â”‚ x â”‚  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”¤
â”‚ t=1 readout_action (1 tokens)      â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚  â”‚   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”´â”€â”€â”€â”´â”€â”€â”˜

[3m                               OctoModule Summary                               [0m
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m [0m[1mpath         [0m[1m [0mâ”ƒ[1m [0m[1mmodule       [0m[1m [0mâ”ƒ[1m [0m[1minputs       [0m[1m [0mâ”ƒ[1m [0m[1moutputs      [0m[1m [0mâ”ƒ[1m [0m[1mparams      [0m[1m [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚               â”‚ OctoModule    â”‚ -             â”‚ - obs:        â”‚              â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ [2mbool[0m[1,2,343] â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚   obs_primarâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚ [2mbool[0m[1,2,256] â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚   obs_propriâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚ [2mbool[0m[1,2,7]   â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚   obs_task_lâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚ [2mbool[0m[1,2,16]  â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚   obs_wrist:  â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚ [2mbool[0m[1,2,64]  â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚   readout_acâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚   task:       â”‚              â”‚
â”‚               â”‚               â”‚ - [2mbool[0m[1,2]   â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚   verbose:    â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚   task_languâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚               â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚               â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ - action:     â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ OctoTransforâ€¦ â”‚ -             â”‚ obs:          â”‚ obs_primaryâ€¦ â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚   mask:       â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ [2mbool[0m[1,2,343] â”‚ obs_proprioâ€¦ â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚   tokens:     â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ obs_wrist_pâ€¦ â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚ obs_primary:  â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚   mask:       â”‚ readout_actâ€¦ â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚ [2mbool[0m[1,2,256] â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚   tokens:     â”‚ task_languaâ€¦ â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚     proprio:  â”‚ obs_proprio:  â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚   mask:       â”‚ [1m1,265,664 [0m   â”‚
â”‚               â”‚               â”‚     timestep: â”‚ [2mbool[0m[1,2,7]   â”‚ [1;2m(5.1 MB)[0m     â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ obs_task_lanâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚ [2mbool[0m[1,2,16]  â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚ obs_wrist:    â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚ [2mbool[0m[1,2,64]  â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚ readout_actiâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚ task:         â”‚              â”‚
â”‚               â”‚               â”‚ - [2mbool[0m[1,2]   â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚   verbose:    â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚ task_languagâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚               â”‚   mask:       â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚               â”‚   tokens:     â”‚              â”‚
â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder       â”‚ FlaxT5Stack   â”‚ attention_maâ€¦ â”‚ attentions:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,1]    â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ deterministiâ€¦ â”‚ cross_attentâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ input_ids:    â”‚ hidden_stateâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,1]    â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ output_attenâ€¦ â”‚ last_hidden_â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ output_hiddeâ€¦ â”‚ past_key_valâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ return_dict:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ shared        â”‚ Embed         â”‚ [2mint32[0m[1,1]    â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/dropâ€¦ â”‚ Dropout       â”‚ -             â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,1,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ deterministiâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/block â”‚ FlaxT5BlockCâ€¦ â”‚ -             â”‚ attentions:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,1,â€¦ â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚ cross_attentâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ attention_maâ€¦ â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,1]    â”‚ hidden_stateâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚   determinisâ€¦ â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚ last_hidden_â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   encoder_atâ€¦ â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ None          â”‚ past_key_valâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚   encoder_hiâ€¦ â”‚ None          â”‚              â”‚
â”‚               â”‚               â”‚ None          â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   init_cache: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   output_attâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   output_hidâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/finaâ€¦ â”‚ FlaxT5LayerNâ€¦ â”‚ [2mfloat32[0m[1,1,â€¦ â”‚ [2mfloat32[0m[1,1,â€¦ â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ LanguageTokeâ€¦ â”‚ -             â”‚ mask:         â”‚ [1m109,628,544 [0m â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚ [2mbool[0m[1,16]    â”‚ [1;2m(438.5 MB)[0m   â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ tokens:       â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,16â€¦ â”‚ [2mfloat32[0m[1,16â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384] â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[768â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m295,296 [0m[1;2m(1.2[0m â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2mMB)[0m          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ ImageTokenizâ€¦ â”‚ -             â”‚ mask:         â”‚ [1m1,058,048 [0m   â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚ [2mbool[0m[1,2,256] â”‚ [1;2m(4.2 MB)[0m     â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ tokens:       â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384] â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[512â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m196,992 [0m     â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2m(788.0 KB)[0m   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ ImageTokenizâ€¦ â”‚ -             â”‚ mask:         â”‚ [1m1,058,048 [0m   â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚ [2mbool[0m[1,2,64]  â”‚ [1;2m(4.2 MB)[0m     â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ tokens:       â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384] â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[512â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m196,992 [0m     â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2m(788.0 KB)[0m   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ LowdimObsTokâ€¦ â”‚ -             â”‚ mask:         â”‚              â”‚
â”‚               â”‚               â”‚ image_primarâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,25â€¦ â”‚ tokens:       â”‚              â”‚
â”‚               â”‚               â”‚   image_wrisâ€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ [2muint8[0m[1,2,12â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_prâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     image_wrâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     proprio:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     timestep: â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   proprio:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_complâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,4]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,2]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   timestep_pâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2]     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ -             â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ language_insâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     attentioâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     input_idâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mint32[0m[1,16]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   pad_mask_dâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     languageâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1]       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384] â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[256â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m98,688 [0m      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2m(394.8 KB)[0m   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transfoâ€¦ â”‚ BlockTransfoâ€¦ â”‚ - -           â”‚ - -           â”‚ [1m21,294,336 [0m  â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚ [1;2m(85.2 MB)[0m    â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚ [2mbool[0m[1,16]    â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ task_language â”‚ task_language â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚ [2mfloat32[0m[1,16â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ - -           â”‚ - -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,256] â”‚ [2mbool[0m[1,2,256] â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ obs_primary   â”‚ obs_primary   â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   -           â”‚   -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,64]  â”‚ [2mbool[0m[1,2,64]  â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ obs_wrist     â”‚ obs_wrist     â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   -           â”‚   -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,7]   â”‚ [2mbool[0m[1,2,7]   â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ obs_proprio   â”‚ obs_proprio   â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   -           â”‚   -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,16]  â”‚ [2mbool[0m[1,2,16]  â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ obs_task_lanâ€¦ â”‚ obs_task_lanâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚   -           â”‚   -           â”‚              â”‚
â”‚               â”‚               â”‚ attention_ruâ€¦ â”‚ attention_ruâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       obs_*:  â”‚       obs_*:  â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       readouâ€¦ â”‚       readouâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚       task_*: â”‚       task_*: â”‚              â”‚
â”‚               â”‚               â”‚ <AttentionRuâ€¦ â”‚ <AttentionRuâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ other.timestâ€¦ â”‚ other.timestâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚ <=            â”‚ <=            â”‚              â”‚
â”‚               â”‚               â”‚ self.timesteâ€¦ â”‚ self.timesteâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚     mask:     â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚     name:     â”‚     name:     â”‚              â”‚
â”‚               â”‚               â”‚ readout_actiâ€¦ â”‚ readout_actiâ€¦ â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚     tokens:   â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   verbose:    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ True          â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action  â”‚ L1ActionHead  â”‚ - obs:        â”‚ [2mfloat32[0m[1,2,â€¦ â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,343] â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   obs_primarâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,256] â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   obs_propriâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,7]   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   obs_task_lâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,16]  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   obs_wrist:  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,2,64]  â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   readout_acâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task:       â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚   task_languâ€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     mask:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mbool[0m[1,16]    â”‚               â”‚              â”‚
â”‚               â”‚               â”‚     tokens:   â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,16â€¦ â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_actionâ€¦ â”‚ MAPHead       â”‚ - mask:       â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ probe:       â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚ [2mfloat32[0m[1,1â€¦ â”‚
â”‚               â”‚               â”‚   tokens:     â”‚               â”‚              â”‚
â”‚               â”‚               â”‚ [2mfloat32[0m[1,2,â€¦ â”‚               â”‚ [1m1,774,080 [0m   â”‚
â”‚               â”‚               â”‚ - train:      â”‚               â”‚ [1;2m(7.1 MB)[0m     â”‚
â”‚               â”‚               â”‚ False         â”‚               â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_actionâ€¦ â”‚ Dense         â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ [2mfloat32[0m[1,2,â€¦ â”‚ bias:        â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[28]  â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ kernel:      â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [2mfloat32[0m[384â€¦ â”‚
â”‚               â”‚               â”‚               â”‚               â”‚              â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1m10,780 [0m[1;2m(43.1[0m â”‚
â”‚               â”‚               â”‚               â”‚               â”‚ [1;2mKB)[0m          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚[1m [0m[1m             [0m[1m [0mâ”‚[1m [0m[1m             [0m[1m [0mâ”‚[1m [0m[1m             [0m[1m [0mâ”‚[1m [0m[1m        Total[0m[1m [0mâ”‚[1m [0m[1m136,877,468 [0m[1m [0mâ”‚
â”‚[1m               [0mâ”‚[1m               [0mâ”‚[1m               [0mâ”‚[1m               [0mâ”‚[1m [0m[1;2m(547.5 MB)[0m[1m  [0m[1m [0mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1m                                                                                [0m
[1m                    Total Parameters: 136,877,468 [0m[1;2m(547.5 MB)[0m[1m                    [0m
I0507 20:31:10.953804 128789240575808 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
I0507 20:31:10.982781 128789240575808 tokenizers.py:124] No task inputs matching image_wrist were found. Replacing with zero padding.
I0507 20:31:11.014965 128789240575808 octo_module.py:219] repeating task tokens at each timestep to perform cross-modal attention
I0507 20:31:15.308497 128789240575808 compiler.py:323] Persistent compilation cache hit for 'jit__init'
I0507 20:31:15.329601 128789240575808 train_utils.py:405] ########## Parameters skipped during model loading: ##########
I0507 20:31:15.329764 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.bias
I0507 20:31:15.329812 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.scale
I0507 20:31:15.329844 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.bias
I0507 20:31:15.329875 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.kernel
I0507 20:31:15.329907 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.bias
I0507 20:31:15.329935 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.kernel
I0507 20:31:15.329965 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.bias
I0507 20:31:15.329994 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.kernel
I0507 20:31:15.330024 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.bias
I0507 20:31:15.330052 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.kernel
I0507 20:31:15.330081 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.bias
I0507 20:31:15.330109 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.kernel
I0507 20:31:15.330142 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.bias
I0507 20:31:15.330170 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.kernel
I0507 20:31:15.330200 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.probe
I0507 20:31:15.330228 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.bias
I0507 20:31:15.330255 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.kernel
I0507 20:31:15.330283 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_pos_embedding
I0507 20:31:15.330309 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.bias
I0507 20:31:15.330334 128789240575808 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.kernel
I0507 20:31:15.331072 128789240575808 train_utils.py:250] Freezing parameters that include the following keys: ['*hf_model*'].
I0507 20:31:15.332822 128789240575808 train_utils.py:286] Num trainable params: 27,248,924.
I0507 20:31:15.332895 128789240575808 train_utils.py:287] Num frozen params: 109,628,544.
I0507 20:31:15.332935 128789240575808 train_utils.py:288] To see a detailed list of frozen params, set logging level to DEBUG.
I0507 20:31:15.940233 128789240575808 finetune.py:180] Starting finetuning...
  0%|                                                 | 0/50000 [00:00<?, ?it/s]I0507 20:31:16.500929 128789240575808 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
I0507 20:31:16.597258 128789240575808 tokenizers.py:124] No task inputs matching image_wrist were found. Replacing with zero padding.
I0507 20:31:16.671689 128789240575808 octo_module.py:219] repeating task tokens at each timestep to perform cross-modal attention
/home/hyperdog/anaconda3/envs/octo/lib/python3.10/site-packages/jax/_src/compiler.py:365: UserWarning: Error reading persistent compilation cache entry for 'jit_train_step': XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/hlo/ir/hlo_module.cc:511) !ContainsKey(instruction_names, instruction->name()) Instruction name is not unique: constant_4820
  warnings.warn(
I0507 20:31:36.245680 128789240575808 compilation_cache.py:101] Writing jit_train_step to persistent compilation cache with key jit_train_step-cba8614418794061162feefcde90964232b7cb51f78cbae5424242c04e43071b.
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 9999/50000 [34:54<2:50:06,  3.92it/s]I0507 21:06:11.347582 128789240575808 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/init/9999.orbax-checkpoint-tmp-1746641171318394/default.
I0507 21:06:12.215929 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/9999.orbax-checkpoint-tmp-1746641171318394/default.orbax-checkpoint-tmp-1746641171347786 to /home/hyperdog/thesis/checkpoints/init/9999.orbax-checkpoint-tmp-1746641171318394/default
I0507 21:06:12.216172 128789240575808 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/init/9999.orbax-checkpoint-tmp-1746641171318394/default`.
I0507 21:06:12.217376 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/9999.orbax-checkpoint-tmp-1746641171318394 to /home/hyperdog/thesis/checkpoints/init/9999
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 19999/50000 [1:09:20<1:39:11,  5.04it/s]I0507 21:40:37.360715 128789240575808 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/init/19999.orbax-checkpoint-tmp-1746643237358829/default.
I0507 21:40:38.190773 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/19999.orbax-checkpoint-tmp-1746643237358829/default.orbax-checkpoint-tmp-1746643237360874 to /home/hyperdog/thesis/checkpoints/init/19999.orbax-checkpoint-tmp-1746643237358829/default
I0507 21:40:38.191041 128789240575808 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/init/19999.orbax-checkpoint-tmp-1746643237358829/default`.
I0507 21:40:38.192110 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/19999.orbax-checkpoint-tmp-1746643237358829 to /home/hyperdog/thesis/checkpoints/init/19999
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 29999/50000 [1:43:21<1:04:25,  5.17it/s]I0507 22:14:38.534604 128789240575808 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/init/29999.orbax-checkpoint-tmp-1746645278532809/default.
I0507 22:14:39.409243 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/29999.orbax-checkpoint-tmp-1746645278532809/default.orbax-checkpoint-tmp-1746645278534753 to /home/hyperdog/thesis/checkpoints/init/29999.orbax-checkpoint-tmp-1746645278532809/default
I0507 22:14:39.409490 128789240575808 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/init/29999.orbax-checkpoint-tmp-1746645278532809/default`.
I0507 22:14:39.410778 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/29999.orbax-checkpoint-tmp-1746645278532809 to /home/hyperdog/thesis/checkpoints/init/29999
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 39999/50000 [2:17:19<32:20,  5.15it/s]I0507 22:48:35.709845 128789240575808 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/init/39999.orbax-checkpoint-tmp-1746647315708183/default.
I0507 22:48:36.577682 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/39999.orbax-checkpoint-tmp-1746647315708183/default.orbax-checkpoint-tmp-1746647315710049 to /home/hyperdog/thesis/checkpoints/init/39999.orbax-checkpoint-tmp-1746647315708183/default
I0507 22:48:36.577927 128789240575808 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/init/39999.orbax-checkpoint-tmp-1746647315708183/default`.
I0507 22:48:36.579008 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/39999.orbax-checkpoint-tmp-1746647315708183 to /home/hyperdog/thesis/checkpoints/init/39999
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 49999/50000 [2:51:25<00:00,  5.19it/s]I0507 23:22:41.741968 128789240575808 checkpointer.py:134] Saving item to /home/hyperdog/thesis/checkpoints/init/49999.orbax-checkpoint-tmp-1746649361739995/default.
I0507 23:22:42.693977 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/49999.orbax-checkpoint-tmp-1746649361739995/default.orbax-checkpoint-tmp-1746649361742120 to /home/hyperdog/thesis/checkpoints/init/49999.orbax-checkpoint-tmp-1746649361739995/default
I0507 23:22:42.694257 128789240575808 utils.py:573] Finished saving checkpoint to `/home/hyperdog/thesis/checkpoints/init/49999.orbax-checkpoint-tmp-1746649361739995/default`.
I0507 23:22:42.695506 128789240575808 utils.py:529] Renaming /home/hyperdog/thesis/checkpoints/init/49999.orbax-checkpoint-tmp-1746649361739995 to /home/hyperdog/thesis/checkpoints/init/49999
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [2:51:26<00:00,  4.86it/s]
